{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from numpy import array\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from numpy.linalg import inv\n",
    "from mediapipe.tasks.python.components.containers import Detection, DetectionResult, BoundingBox, Category\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fused_Workflow:\n",
    "    def __init__(self, iou_threshold, decision_making_mode, max_results, score_threshold):\n",
    "        \"\"\"Project FUSED Workflow Algorithm (refactored for analysis)\n",
    "\n",
    "        Args:\n",
    "            iou_threshold (float): Intersection-over-Union fraction threshold for evaluating bounding box overlaps\n",
    "            decision_making_mode (str): Which sensors need to agree for the detection to be considered valid? 'all', 'thermal', or 'webcam'\n",
    "            score_threshold (float): Minimum confidence score that the models must have for the detection to be kept\n",
    "        \"\"\"\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.decision_making_mode = decision_making_mode\n",
    "        \n",
    "        # Initialize the object detection models\n",
    "        base_options_webcam = python.BaseOptions(model_asset_path='/project_fused/models/efficientdet_lite0.tflite')\n",
    "        options_webcam = vision.ObjectDetectorOptions(base_options=base_options_webcam, running_mode=vision.RunningMode.IMAGE, max_results=max_results, score_threshold=score_threshold)\n",
    "        self.webcam_detector = vision.ObjectDetector.create_from_options(options_webcam)\n",
    "\n",
    "        # Initialize the thermal object detection model\n",
    "        base_options_thermal = python.BaseOptions(model_asset_path='/project_fused/models/thermal.tflite')\n",
    "        options_thermal = vision.ObjectDetectorOptions(base_options=base_options_thermal, running_mode=vision.RunningMode.IMAGE, max_results=max_results, score_threshold=score_threshold)\n",
    "        self.thermal_detector = vision.ObjectDetector.create_from_options(options_thermal)\n",
    "\n",
    "        # Initialize the LiDAR object detection model\n",
    "        base_options_lidar = python.BaseOptions(model_asset_path='/project_fused/models/lidar.tflite')\n",
    "        options_lidar = vision.ObjectDetectorOptions(base_options=base_options_lidar, running_mode=vision.RunningMode.IMAGE, max_results=max_results, score_threshold=score_threshold)\n",
    "        self.lidar_detector = vision.ObjectDetector.create_from_options(options_lidar)\n",
    "\n",
    "        # Define the transformation matrices\n",
    "        # Set extrinsic translation matrices based on physical measurements, no z translation assumed\n",
    "        self.T_l2t = array([[1, 0, 0, 0.028],\n",
    "                            [0, 1, 0, -0.038],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "        self.T_l2w = array([[1, 0, 0, 0.083],\n",
    "                            [0, 1, 0, -0.035],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "        # Set extrinsic rotation matrices from stereo calibration\n",
    "        self.R_t2cₜ = array([[0.804905, 0.593319, 0.010014],\n",
    "                             [-0.588094, 0.795337, 0.146920],\n",
    "                             [0.079206, -0.124146, 0.989098]])\n",
    "        self.R_l2cₜ = array([[0.813639, 0.571181, 0.108367],\n",
    "                             [-0.580035, 0.784919, 0.217856],\n",
    "                             [0.039376, -0.240112, 0.969946]])\n",
    "        self.R_w2cᵣ = array([[0.903012, -0.397065, -0.164039],\n",
    "                             [0.397183, 0.917127, -0.033513],\n",
    "                             [0.163751, -0.034891, 0.985884]])\n",
    "        self.R_l2cᵣ = array([[0.909488, -0.399788, -0.114025],\n",
    "                             [0.399705, 0.916314, -0.024592],\n",
    "                             [0.114314, -0.023211, 0.993173]])\n",
    "\n",
    "        # Set intrinsic matrices for the three sensors\n",
    "        self.Kₗ = array([[205.046875, 0.0, 107.55435943603516],\n",
    "                         [0.0, 205.046875, 82.43924713134766],\n",
    "                         [0.0, 0.0, 1.0]])\n",
    "        self.Kₜ = array([[161.393925, 0.000000, 78.062273],\n",
    "                         [0.000000, 161.761028, 59.925115], \n",
    "                         [0.000000, 0.000000, 1.000000]])\n",
    "        self.Kᵣ = array([[446.423112, 0.000000, 163.485603], \n",
    "                         [0.000000, 446.765896, 131.217485],\n",
    "                         [0.000000, 0.000000, 1.000000]])\n",
    "\n",
    "        # Initialize visualization parameters\n",
    "        self.TEXT_COLOR = (255, 255, 255)\n",
    "        self.BOX_THICKNESS = 3\n",
    "        self.MARGIN = 5\n",
    "        self.ROW_SIZE = -15\n",
    "        self.FONT_SIZE = 0.5\n",
    "        self.FONT_THICKNESS = 1\n",
    "        \n",
    "        # Initialize image resolutions\n",
    "        self.lidar_width = 224\n",
    "        self.lidar_height = 172\n",
    "        self.thermal_width = 160\n",
    "        self.thermal_height = 120\n",
    "        self.webcam_width = 320\n",
    "        self.webcam_height = 240\n",
    "        \n",
    "    def fuse(self, lidar_image, thermal_image, webcam_image):\n",
    "        \"\"\"Main FUSED workflow function: perform fusion based alignment of object detection\n",
    "        bounding boxes on synchronized LiDAR, thermal, and webcam images for decision making\n",
    "\n",
    "        Args:\n",
    "            lidar_image (OpenCV image): Synchronized LiDAR image\n",
    "            thermal_image (OpenCV image): Synchronized thermal image\n",
    "            webcam_image (OpenCV image): Synchronized webcam image\n",
    "\n",
    "        Returns:\n",
    "            detection results (tuple): 6 detection results - 3 from individual sensors, 3 from FUSED workflow\n",
    "        \"\"\"\n",
    "        # Perform LiDAR image processing\n",
    "        max_depth = np.max(lidar_image)\n",
    "        lidar_image_clipped = np.clip(lidar_image, 0, max_depth)\n",
    "        lidar_image_mm = lidar_image_clipped * 1000\n",
    "        lidar_image_normalized = cv2.normalize(lidar_image_mm, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "        lidar_image_8bit = cv2.convertScaleAbs(lidar_image_normalized, alpha=(255.0 / np.max(lidar_image_normalized)))\n",
    "        lidar_image_equalized = cv2.equalizeHist(lidar_image_8bit)\n",
    "\n",
    "        # Convert OpenCV images to RGB format\n",
    "        lidar_image_rgb = cv2.cvtColor(lidar_image_equalized, cv2.COLOR_GRAY2RGB)\n",
    "        thermal_image_rgb = cv2.cvtColor(thermal_image, cv2.COLOR_GRAY2RGB)\n",
    "        webcam_image_rgb = cv2.cvtColor(webcam_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert RGB images to MediaPipe images\n",
    "        lidar_image_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=lidar_image_rgb)\n",
    "        thermal_image_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=thermal_image_rgb)\n",
    "        webcam_image_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=webcam_image_rgb)\n",
    "\n",
    "        # Perform object detection on the MediaPipe images\n",
    "        lidar_detection_result = self.lidar_detector.detect(lidar_image_mp)\n",
    "        thermal_detection_result = self.thermal_detector.detect(thermal_image_mp)\n",
    "        webcam_detection_result = self.webcam_detector.detect(webcam_image_mp)\n",
    "\n",
    "        # Initialize lists for keeping track of detections to be kept out of the next iteration\n",
    "        thermal_exclude_idx = []\n",
    "        webcam_exclude_idx = []\n",
    "        \n",
    "        # Initialize detection lists for the fused results\n",
    "        lidar_fused_detections = []\n",
    "        thermal_fused_detections = []\n",
    "        webcam_fused_detections = []\n",
    "\n",
    "        # For loop through each LiDAR detection in the detection result\n",
    "        if lidar_detection_result.detections:\n",
    "            for detection in lidar_detection_result.detections:\n",
    "                if detection.categories[0].category_name != 'Person':\n",
    "                    continue\n",
    "                # Define the top left and bottom right points of the detection\n",
    "                bbox = detection.bounding_box\n",
    "                x1, y1 = bbox.origin_x, bbox.origin_y # Top left\n",
    "                x2, y2 = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height # Bottom right\n",
    "\n",
    "                # Find the depth on the LiDAR image at the center of the box\n",
    "                uₗ = round((x1 + x2) / 2)\n",
    "                vₗ = round((y1 + y2) / 2)\n",
    "                try:\n",
    "                    zₗ = lidar_image[vₗ,uₗ]\n",
    "                except IndexError:\n",
    "                    if uₗ >= lidar_image.shape[1]:\n",
    "                        uₗ = lidar_image.shape[1] - 1\n",
    "                    if vₗ >= lidar_image.shape[0]:\n",
    "                        vₗ = lidar_image.shape[0] - 1\n",
    "                    zₗ = lidar_image[vₗ, uₗ]\n",
    "\n",
    "                # If depth is not zero, then compute transformed u and v on webcam and thermal frames\n",
    "                if zₗ > 1E-3:\n",
    "                    x1ₗₜ, y1ₗₜ, x1ₗᵣ, y1ₗᵣ = self.transform(zₗ, x1, y1)\n",
    "                    x2ₗₜ, y2ₗₜ, x2ₗᵣ, y2ₗᵣ = self.transform(zₗ, x2, y2)\n",
    "\n",
    "                    # Calculate IoU between the mapped bounding box and all detection results from the webcam and thermal images\n",
    "                    thermal_mapped_box = (x1ₗₜ, y1ₗₜ, x2ₗₜ, y2ₗₜ)\n",
    "                    if thermal_detection_result.detections and len(thermal_detection_result.detections) != len(thermal_exclude_idx):\n",
    "                        thermal_ious = []\n",
    "                        for idxₜ, thermal_detection in enumerate(thermal_detection_result.detections):\n",
    "                            if thermal_detection.categories[0].category_name != 'Person':\n",
    "                                thermal_ious.append(0.0)\n",
    "                                continue\n",
    "                            if idxₜ in thermal_exclude_idx:\n",
    "                                thermal_ious.append(0.0)\n",
    "                                continue\n",
    "                            thermal_bbox = thermal_detection.bounding_box\n",
    "                            x1ₜ, y1ₜ = thermal_bbox.origin_x, thermal_bbox.origin_y\n",
    "                            x2ₜ, y2ₜ = thermal_bbox.origin_x + thermal_bbox.width, thermal_bbox.origin_y + thermal_bbox.height\n",
    "                            thermal_box = (x1ₜ, y1ₜ, x2ₜ, y2ₜ)\n",
    "                            thermal_ious.append(self.calc_iou(thermal_box, thermal_mapped_box))\n",
    "\n",
    "                    webcam_mapped_box = (x1ₗᵣ, y1ₗᵣ, x2ₗᵣ, y2ₗᵣ)\n",
    "                    if webcam_detection_result.detections and len(webcam_detection_result.detections) != len(webcam_exclude_idx):\n",
    "                        webcam_ious = []\n",
    "                        for idxᵣ, webcam_detection in enumerate(webcam_detection_result.detections):\n",
    "                            if webcam_detection.categories[0].category_name != 'person':\n",
    "                                webcam_ious.append(0.0)\n",
    "                                continue\n",
    "                            if idxᵣ in webcam_exclude_idx:\n",
    "                                webcam_ious.append(0.0)\n",
    "                                continue\n",
    "                            webcam_bbox = webcam_detection.bounding_box\n",
    "                            x1ᵣ, y1ᵣ = webcam_bbox.origin_x, webcam_bbox.origin_y\n",
    "                            x2ᵣ, y2ᵣ = webcam_bbox.origin_x + webcam_bbox.width, webcam_bbox.origin_y + webcam_bbox.height\n",
    "                            webcam_box = (x1ᵣ, y1ᵣ, x2ᵣ, y2ᵣ)\n",
    "                            webcam_ious.append(self.calc_iou(webcam_box, webcam_mapped_box))\n",
    "\n",
    "                    # Choose the thermal or webcam detection result corresponding to the LiDAR mapped result whose IoU is the \n",
    "                    # largest and also above the defined Combination IoU threshold. In the next iterations of the for loop,\n",
    "                    # the thermal or webcam detection result that was chosen should not be chosen again to match with another\n",
    "                    # LiDAR mapped result\n",
    "                    valid_thermal_iou = None\n",
    "                    valid_webcam_iou = None\n",
    "                    if thermal_detection_result.detections and len(thermal_detection_result.detections) != len(thermal_exclude_idx):\n",
    "                        max_thermal_iou = max(thermal_ious)\n",
    "                        max_thermal_iou_index = thermal_ious.index(max_thermal_iou)\n",
    "                        valid_thermal_iou = 0\n",
    "                        if max_thermal_iou > self.iou_threshold:\n",
    "                            valid_thermal_iou, valid_thermal_idx = max_thermal_iou, max_thermal_iou_index\n",
    "                            thermal_exclude_idx.append(valid_thermal_idx)\n",
    "                    \n",
    "                    if webcam_detection_result.detections and len(webcam_detection_result.detections) != len(webcam_exclude_idx):\n",
    "                        max_webcam_iou = max(webcam_ious)\n",
    "                        max_webcam_iou_index = webcam_ious.index(max_webcam_iou)\n",
    "                        valid_webcam_iou = 0\n",
    "                        if max_webcam_iou > self.iou_threshold:\n",
    "                            valid_webcam_iou, valid_webcam_idx = max_webcam_iou, max_webcam_iou_index\n",
    "                            webcam_exclude_idx.append(valid_webcam_idx)\n",
    "\n",
    "                    # Depending on the decision making mode, choose to either keep the mapped result or not based on whether there \n",
    "                    # is agreement between all 3 or only two sensors\n",
    "                    # If the mapped result is not being kept, then go to the next iteration of the loop. If it is being kept, then\n",
    "                    # keep the original detections that have been agreed upon according to the decision making mode. For the \n",
    "                    # detection that has not been agreed upon, check if it agrees with LiDAR. If it does, keep it. If it does not,\n",
    "                    # then use the mapped LiDAR detection onto the appropriate camera frame instead\n",
    "                    # Store the three fused detection results at each iteration\n",
    "                    if self.decision_making_mode == 'all':\n",
    "                        if valid_thermal_iou and valid_webcam_iou:\n",
    "                            lidar_fused_detections.append(self.truncate(detection, self.lidar_width, self.lidar_height))\n",
    "                            thermal_fused_detections.append(self.truncate(thermal_detection_result.detections[valid_thermal_idx], self.thermal_width, self.thermal_height))\n",
    "                            webcam_fused_detections.append(self.truncate(webcam_detection_result.detections[valid_webcam_idx], self.webcam_width, self.webcam_height))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    if self.decision_making_mode == 'thermal':\n",
    "                        if valid_thermal_iou:\n",
    "                            lidar_fused_detections.append(self.truncate(detection, self.lidar_width, self.lidar_height))\n",
    "                            thermal_fused_detections.append(self.truncate(thermal_detection_result.detections[valid_thermal_idx], self.thermal_width, self.thermal_height))\n",
    "                            if valid_webcam_iou:\n",
    "                                webcam_fused_detections.append(self.truncate(webcam_detection_result.detections[valid_webcam_idx], self.webcam_width, self.webcam_height))\n",
    "                            else:\n",
    "                                webcam_fused_detections.append(self.truncate(self.create_detection(detection, webcam_mapped_box), self.webcam_width, self.webcam_height))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    if self.decision_making_mode == 'webcam':\n",
    "                        if valid_webcam_iou:\n",
    "                            lidar_fused_detections.append(self.truncate(detection, self.lidar_width, self.lidar_height))\n",
    "                            webcam_fused_detections.append(self.truncate(webcam_detection_result.detections[valid_webcam_idx], self.webcam_width, self.webcam_height))\n",
    "                            if valid_thermal_iou:\n",
    "                                thermal_fused_detections.append(self.truncate(thermal_detection_result.detections[valid_thermal_idx], self.thermal_width, self.thermal_height))\n",
    "                            else:\n",
    "                                thermal_fused_detections.append(self.truncate(self.create_detection(detection, thermal_mapped_box), self.thermal_width, self.thermal_height))\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        # With all of the fused detections, create detection results\n",
    "        if not lidar_fused_detections:\n",
    "            lidar_fused_detection_result = None\n",
    "        else:\n",
    "            lidar_fused_detection_result = DetectionResult(detections=lidar_fused_detections)\n",
    "            \n",
    "        if not thermal_fused_detections:\n",
    "            thermal_fused_detection_result = None\n",
    "        else:\n",
    "            thermal_fused_detection_result = DetectionResult(detections=thermal_fused_detections)\n",
    "            \n",
    "        if not webcam_fused_detections:\n",
    "            webcam_fused_detection_result = None\n",
    "        else:\n",
    "            webcam_fused_detection_result = DetectionResult(detections=webcam_fused_detections)\n",
    "            \n",
    "        return lidar_detection_result, thermal_detection_result, webcam_detection_result, lidar_fused_detection_result, thermal_fused_detection_result, webcam_fused_detection_result\n",
    "            \n",
    "    def transform(self, zₗ, uₗ, vₗ):\n",
    "        \"\"\"Perform transformations to map a pixel from the LiDAR's camera frame onto the thermal and webcam camera frames\n",
    "\n",
    "        Args:\n",
    "            zₗ (float): Depth of the pixel, in meters\n",
    "            uₗ (int): LiDAR pixel coordinate on the x axis\n",
    "            vₗ (int): LiDAR pixel coordinate on the y axis\n",
    "\n",
    "        Returns:\n",
    "            uₜ, vₜ, uᵣ, vᵣ (tuple): Thermal and webcam pixel coordinates, respectively\n",
    "        \"\"\"\n",
    "        # Calculate the 3D physical coordinate of the center of the LiDAR image\n",
    "        pₗ = array([uₗ, vₗ, 1])\n",
    "        l̂ₗ = inv(self.Kₗ) @ pₗ\n",
    "        r̄ₗ = zₗ * l̂ₗ\n",
    "        \n",
    "        # Perform extrinsic translations to the thermal sensor and webcam\n",
    "        r̄ₜ = (inv(self.R_t2cₜ) @ (self.R_l2cₜ @ r̄ₗ)) + array([self.T_l2t[0, 3], self.T_l2t[1, 3], 0]).T\n",
    "        r̄ᵣ = (inv(self.R_w2cᵣ) @ (self.R_l2cᵣ @ r̄ₗ)) + array([self.T_l2w[0, 3], self.T_l2w[1, 3], 0]).T\n",
    "        \n",
    "        # Transform 3D coordinate to thermal and webcam pixel coordinates\n",
    "        r̃ₜ = array([r̄ₜ[0]/r̄ₜ[2], r̄ₜ[1]/r̄ₜ[2], r̄ₜ[2]/r̄ₜ[2]])\n",
    "        r̃ᵣ = array([r̄ᵣ[0]/r̄ᵣ[2], r̄ᵣ[1]/r̄ᵣ[2], r̄ᵣ[2]/r̄ᵣ[2]])\n",
    "        pₜ = self.Kₜ @ r̃ₜ\n",
    "        pᵣ = self.Kᵣ @ r̃ᵣ\n",
    "        uₜ, vₜ = pₜ[0], pₜ[1]\n",
    "        uᵣ, vᵣ = pᵣ[0], pᵣ[1]\n",
    "        \n",
    "        return uₜ, vₜ, uᵣ, vᵣ\n",
    "    \n",
    "    def calc_iou(self, box_1, box_2):\n",
    "        \"\"\"Calculate the Intersection-over-Union between two bounding boxes\n",
    "\n",
    "        Args:\n",
    "            box_1 (tuple): Tuple of top-left and bottom-right pixel coordinates for the first bounding box\n",
    "            box_2 (tuple): Tuple of top-left and bottom-right pixel coordinates for the second bounding box\n",
    "\n",
    "        Returns:\n",
    "            iou (float): Intersection-over-Union ratio\n",
    "        \"\"\"\n",
    "        # Get corner values from both boxes\n",
    "        x1, y1, x2, y2 = box_1\n",
    "        x3, y3, x4, y4 = box_2\n",
    "        \n",
    "        # Get corner values for the intersection box\n",
    "        x_inter1 = max(x1, x3)\n",
    "        y_inter1 = max(y1, y3)\n",
    "        x_inter2 = min(x2, x4)\n",
    "        y_inter2 = min(y2, y4)\n",
    "        \n",
    "        # Calculate the area of the intersection box\n",
    "        width_inter = max(0, x_inter2 - x_inter1)\n",
    "        height_inter = max(0, y_inter2 - y_inter1)\n",
    "        area_inter = width_inter * height_inter\n",
    "        \n",
    "        # Calculate the areas of the two boxes\n",
    "        width_box1 = x2 - x1\n",
    "        height_box1 = y2 - y1\n",
    "        width_box2 = x4 - x3\n",
    "        height_box2 = y4 - y3\n",
    "        area_box1 = width_box1 * height_box1\n",
    "        area_box2 = width_box2 * height_box2\n",
    "        \n",
    "        # Calculate the area of the full union of the two boxes\n",
    "        area_union = area_box1 + area_box2 - area_inter\n",
    "        \n",
    "        # If union area is zero, return 0\n",
    "        if area_union == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate the IoU\n",
    "        iou = area_inter / area_union\n",
    "\n",
    "        return iou\n",
    "    \n",
    "    def truncate(self, detection, img_width, img_height): \n",
    "        \"\"\"Truncate a bounding box detection so that the coordinates remain within the image\n",
    "        and don't go over the edges\n",
    "\n",
    "        Args:\n",
    "            detection (object): MediaPipe detection object\n",
    "            img_width (int): Image width (pixels)\n",
    "            img_height (int): Image height (pixels)\n",
    "\n",
    "        Returns:\n",
    "            new_detection (object): Updated MediaPipe detection object with truncated bounding box coordinates\n",
    "        \"\"\"\n",
    "        # Extract bounding box coordinates\n",
    "        bbox = detection.bounding_box\n",
    "        box_x1 = bbox.origin_x\n",
    "        box_y1 = bbox.origin_y\n",
    "        box_width = bbox.width\n",
    "        box_height = bbox.height\n",
    "        box_x2 = box_x1 + box_width\n",
    "        box_y2 = box_y1 + box_height\n",
    "        \n",
    "        # Fix box corners if they are off the image\n",
    "        if box_x1 < 0:\n",
    "            box_x1 = 0\n",
    "            \n",
    "        if box_x2 > img_width:\n",
    "            box_x2 = img_width\n",
    "            \n",
    "        if box_y1 < 0:\n",
    "            box_y1 = 0\n",
    "            \n",
    "        if box_y2 > img_height:\n",
    "            box_y2 = img_height\n",
    "        \n",
    "        # Calculate new width and height    \n",
    "        box_width = box_x2 - box_x1\n",
    "        box_height = box_y2 - box_y1\n",
    "    \n",
    "        # Redefine bounding box coordinates\n",
    "        detection.bounding_box.origin_x = box_x1\n",
    "        detection.bounding_box.origin_y = box_y1\n",
    "        detection.bounding_box.width = box_width\n",
    "        detection.bounding_box.height = box_height\n",
    "        \n",
    "        return detection\n",
    "    \n",
    "    def create_detection(self, lidar_detection, other_detection_box):\n",
    "        \"\"\"Create a MediaPipe detection object\n",
    "\n",
    "        Args:\n",
    "            lidar_detection (detection object): Original LiDAR MediaPipe detection object\n",
    "            other_detection_box (tuple): Tuple with bounding box coordinates for mapped LiDAR box onto either\n",
    "            webcam or thermal camera frames\n",
    "\n",
    "        Returns:\n",
    "            detection (detection object): MediaPipe detection object for the mapped LiDAR box onto one of the \n",
    "            two other camera frames\n",
    "        \"\"\"\n",
    "        # Get bounding box coordinates and score\n",
    "        x1, y1, x2, y2 = other_detection_box\n",
    "        x1, y1, x2, y2 = round(x1), round(y1), round(x2), round(y2)\n",
    "        score = lidar_detection.categories[0].score\n",
    "        \n",
    "        # Define data dictionary\n",
    "        data = {\n",
    "            \"bounding_box\": (x1, y1, x2 - x1, y2 - y1),\n",
    "            \"score\": score,\n",
    "            \"category_name\": \"Person\"\n",
    "        }\n",
    "        \n",
    "        # Use MediaPipe functions to build the detection object\n",
    "        bounding_box = BoundingBox(\n",
    "            origin_x=data[\"bounding_box\"][0],\n",
    "            origin_y=data[\"bounding_box\"][1],\n",
    "            width=data[\"bounding_box\"][2],\n",
    "            height=data[\"bounding_box\"][3]\n",
    "        )\n",
    "        \n",
    "        category = Category(\n",
    "            index=None, # Optional\n",
    "            score=data[\"score\"],\n",
    "            display_name=None, # Optional\n",
    "            category_name=data[\"category_name\"]\n",
    "        )\n",
    "        \n",
    "        detection = Detection(\n",
    "            bounding_box=bounding_box,\n",
    "            categories=[category],\n",
    "            keypoints=[] # Optional\n",
    "        )\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def visualize(self, image, detection_result):\n",
    "        \"\"\"Draw bounding boxes on OpenCV images\n",
    "\n",
    "        Args:\n",
    "            image (OpenCV image): OpenCV image that the box must be drawn on\n",
    "            detection_result (MediaPipe detection result): MediaPipe detection result containing bounding box coordinates and labels\n",
    "\n",
    "        Returns:\n",
    "            image (OpenCV image): OpenCV image with the boxes and labels drawn\n",
    "        \"\"\"\n",
    "        # Start for loop for all detections \n",
    "        for detection in detection_result.detections:\n",
    "            # Draw the bounding box\n",
    "            bbox = detection.bounding_box\n",
    "            start_point = bbox.origin_x, bbox.origin_y\n",
    "            end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
    "            cv2.rectangle(image, start_point, end_point, self.TEXT_COLOR, self.BOX_THICKNESS)\n",
    "\n",
    "            # Write the label\n",
    "            category = detection.categories[0]\n",
    "            category_name = category.category_name\n",
    "            probability = round(category.score, 2)\n",
    "            result_text = category_name + ' (' + str(probability) + ')'\n",
    "            text_location = (self.MARGIN + bbox.origin_x,\n",
    "                                self.MARGIN + self.ROW_SIZE + bbox.origin_y)\n",
    "            cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_DUPLEX,\n",
    "                        self.FONT_SIZE, self.TEXT_COLOR, self.FONT_THICKNESS, cv2.LINE_AA)\n",
    "            \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_results(i, directory, fused, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, \\\n",
    "        fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results):\n",
    "    \"\"\"Loop through and sort the images required for the FUSED workflow, call the FUSED workflow, and\n",
    "    store detection results and image filenames in arrays\n",
    "\n",
    "    Args:\n",
    "        i (int): Iterator for the for loop\n",
    "        directory (Path object): Path for the directory containing the images\n",
    "        fused (class): Instance of the Fused_Workflow class\n",
    "        idv_lidar_det_results (numpy array): Empty numpy array\n",
    "        idv_thermal_det_results (numpy array): Empty numpy array\n",
    "        idv_webcam_det_results (numpy array): Empty numpy array\n",
    "        fused_thermal_det_results (numpy array): Empty numpy array\n",
    "        fused_webcam_det_results (numpy array): Empty numpy array\n",
    "\n",
    "    Returns:\n",
    "        detection results (tuple): All numpy arrays with detections and image filenames added\n",
    "    \"\"\"\n",
    "    \n",
    "    # For loop through each set of synchronized images\n",
    "    for path in directory.glob('*'):\n",
    "        # Extract category\n",
    "        category = str(path).rsplit('_')[-3]\n",
    "        \n",
    "        # If LiDAR, grab the two corresponding thermal and webcam paths\n",
    "        if category == 'lidar': \n",
    "            # Redefine path variable\n",
    "            lidar_path = path\n",
    "            \n",
    "            # Pull scenario and number for matching files\n",
    "            scenario = '_'.join(str(path).rsplit('/')[-1].rsplit('_')[:-3])\n",
    "            number = str(path).rsplit('_')[-1].rsplit('.')[0]\n",
    "           \n",
    "            # Thermal and webcam path re-creation\n",
    "            thermal_path = directory.joinpath(scenario + '_thermal_image_' + number + '.png')\n",
    "            webcam_path = directory.joinpath(scenario + '_webcam_image_' + number + '.png')\n",
    "           \n",
    "            # Read in images\n",
    "            lidar_image = cv2.imread(lidar_path, cv2.IMREAD_UNCHANGED)\n",
    "            thermal_image = cv2.imread(thermal_path, cv2.IMREAD_UNCHANGED)\n",
    "            webcam_image = cv2.imread(webcam_path, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            # Call the fuse method\n",
    "            idv_lidar, idv_thermal, idv_webcam, fused_lidar, fused_thermal, fused_webcam = fused.fuse(lidar_image, thermal_image, webcam_image)\n",
    "            \n",
    "            # Add individual results to matrices\n",
    "            idv_lidar_det_results[i,0] = lidar_path\n",
    "            idv_lidar_det_results[i,1] = idv_lidar\n",
    "            idv_thermal_det_results[i,0] = thermal_path\n",
    "            idv_thermal_det_results[i,1] = idv_thermal\n",
    "            idv_webcam_det_results[i,0] = webcam_path\n",
    "            idv_webcam_det_results[i,1] = idv_webcam\n",
    "            \n",
    "            # Add fused results to matrices\n",
    "            fused_lidar_det_results[i,0] = lidar_path\n",
    "            fused_lidar_det_results[i,1] = fused_lidar\n",
    "            fused_thermal_det_results[i,0] = thermal_path\n",
    "            fused_thermal_det_results[i,1] = fused_thermal\n",
    "            fused_webcam_det_results[i,0] = webcam_path\n",
    "            fused_webcam_det_results[i,1] = fused_webcam\n",
    "            \n",
    "            # Update iterator\n",
    "            i += 1\n",
    "            \n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    return i, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap(det_results, ground_truth, iou_threshold, fused, title):\n",
    "    # Find total number of images from the matrix\n",
    "    n = det_results.shape[0]\n",
    "    \n",
    "    # Find total number of algorithm detections\n",
    "    det_results_list = det_results[:,1]\n",
    "    total_num_algorithm_detections = 0\n",
    "    for det_res in det_results_list:\n",
    "        if det_res is not None:\n",
    "            total_num_algorithm_detections = total_num_algorithm_detections + len(det_res.detections)\n",
    "    \n",
    "    # Initialize output\n",
    "    ap_detections = np.empty((total_num_algorithm_detections, 4), dtype=object)\n",
    "    \n",
    "    # Find total number of ground truth detections - LiDAR, thermal, or webcam\n",
    "    det_results_category = str(det_results[0,0]).rsplit('_', 3)[-3]\n",
    "    total_num_ground_truth_detections = 0\n",
    "    for annotation in ground_truth['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        for image in ground_truth['images']:\n",
    "            if image['id'] == image_id:\n",
    "                filename = image['file_name']\n",
    "                category = str(filename).rsplit('_', 3)[-3]\n",
    "                if category == det_results_category:\n",
    "                    total_num_ground_truth_detections += 1\n",
    "    \n",
    "    # Initialize iterator for filling in data\n",
    "    j = 0\n",
    "    \n",
    "    # Loop through each image\n",
    "    for i in range(n):\n",
    "        # Define the image filename and the detection result from that image\n",
    "        image_path = det_results[i,0]\n",
    "        filename = image_path.stem + image_path.suffix\n",
    "        det_result = det_results[i,1]\n",
    "        \n",
    "        # Loop through all ground truth images to find the correct ground truth image corresponding to the algorithm image\n",
    "        image_id = None\n",
    "        for image in ground_truth['images']:\n",
    "            if filename == image['file_name']:\n",
    "                image_id = image['id']\n",
    "                break\n",
    "                \n",
    "        # If the image ID is not None (there are ground truth detections in the image), then do the following\n",
    "        if image_id is not None:\n",
    "            # Grab all ground truth detections for the correct image\n",
    "            ground_truth_detections = []\n",
    "            for annotation in ground_truth['annotations']:\n",
    "                if annotation['image_id'] == image_id:\n",
    "                    ground_truth_detections.append(annotation)\n",
    "            \n",
    "            # Define the excluding index list\n",
    "            exclude_idx = []\n",
    "            \n",
    "            # Define counters to see if there are leftover algorithm detections that do not match ground truth detections\n",
    "            num_ground_truth_detections = len(ground_truth_detections)\n",
    "            num_algorithm_detections_so_far = 0\n",
    "            \n",
    "            # Loop through all ground truth detections\n",
    "            for ground_truth_detection in ground_truth_detections:\n",
    "                ground_truth_bbox = ground_truth_detection['bbox']\n",
    "                ground_truth_box = (ground_truth_bbox[0], ground_truth_bbox[1], ground_truth_bbox[0] + ground_truth_bbox[2], ground_truth_bbox[1] + ground_truth_bbox[3])\n",
    "                \n",
    "                # If there are no algorithm detections, then skip\n",
    "                # Also, if the number of algorithm detections is the same as the number of excluded algorithm detections, then skip\n",
    "                # Compute IoUs between all algorithm detections that have not been excluded and the single ground truth detection\n",
    "                if det_result is not None:\n",
    "                    if det_result.detections and len(det_result.detections) != len(exclude_idx):\n",
    "                            ious = []\n",
    "                            for idx, algorithm_detection in enumerate(det_result.detections):\n",
    "                                category = algorithm_detection.categories[0].category_name\n",
    "                                if category != 'Person' and category != 'person':\n",
    "                                    ious.append(0.0)\n",
    "                                    continue\n",
    "                                if idx in exclude_idx:\n",
    "                                    ious.append(0.0)\n",
    "                                    continue\n",
    "                                bbox = algorithm_detection.bounding_box\n",
    "                                x1, y1 = bbox.origin_x, bbox.origin_y\n",
    "                                x2, y2 = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
    "                                algorithm_box = (x1, y1, x2, y2)\n",
    "                                ious.append(fused.calc_iou(algorithm_box, ground_truth_box))\n",
    "                \n",
    "                # If the maximum IoU from the list is larger than the threshold, then the algorithm detection agrees with the ground truth\n",
    "                if det_result is not None:\n",
    "                    if det_result.detections and len(det_result.detections) != len(exclude_idx):\n",
    "                        max_iou = max(ious)\n",
    "                        max_iou_index = ious.index(max_iou)\n",
    "                        if max_iou > iou_threshold:\n",
    "                            valid_idx = max_iou_index\n",
    "                            exclude_idx.append(valid_idx)\n",
    "                            ap_detections[j, 0] = det_result.detections[valid_idx].categories[0].score\n",
    "                            ap_detections[j, 1] = det_result.detections[valid_idx]\n",
    "                            ap_detections[j, 2] = True\n",
    "                            ap_detections[j, 3] = filename\n",
    "                            j += 1\n",
    "                            num_algorithm_detections_so_far += 1\n",
    "                            \n",
    "                        # If the maximum IoU is not larger than the threshold, then continue\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "            # If there are leftover algorithm detections that did not pair with ground truth, then add those as False\n",
    "            if num_algorithm_detections_so_far != num_ground_truth_detections:\n",
    "                if det_result is not None:\n",
    "                    if det_result.detections:\n",
    "                        for idx, algorithm_detection in enumerate(det_result.detections):\n",
    "                            category = algorithm_detection.categories[0].category_name\n",
    "                            if category != 'Person' and category != 'person':\n",
    "                                continue\n",
    "                            if idx in exclude_idx:\n",
    "                                continue\n",
    "                            ap_detections[j, 0] = algorithm_detection.categories[0].score\n",
    "                            ap_detections[j, 1] = algorithm_detection\n",
    "                            ap_detections[j, 2] = False\n",
    "                            ap_detections[j, 3] = filename\n",
    "                            j += 1\n",
    "            \n",
    "        # If image ID is None, then there are no ground truth detections and any algorithm detections are False\n",
    "        else:\n",
    "            if det_result is not None:\n",
    "                if det_result.detections:\n",
    "                    for algorithm_detection in det_result.detections:\n",
    "                        ap_detections[j, 0] = algorithm_detection.categories[0].score\n",
    "                        ap_detections[j, 1] = algorithm_detection\n",
    "                        ap_detections[j, 2] = False\n",
    "                        ap_detections[j, 3] = filename\n",
    "                        j += 1\n",
    "    \n",
    "    # Sort the detections by order of decreasing confidence\n",
    "    ap_detections = ap_detections[ap_detections[:, 0].astype(float).argsort()[::-1]]\n",
    "    \n",
    "    return ap_detections, total_num_ground_truth_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739545626.478825   12200 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1739545626.540128   12200 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\n",
      "I0000 00:00:1739545626.681620   12200 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\n"
     ]
    }
   ],
   "source": [
    "# Get the number of images in the chosen test directory\n",
    "analysis_dataset_dir = Path('/project_fused/data/Analysis_Dataset')\n",
    "num_images_labeled = len(list(analysis_dataset_dir.joinpath('labeled_images').glob('*')))\n",
    "num_images_unlabeled = len(list(analysis_dataset_dir.joinpath('unlabeled_images').glob('*')))\n",
    "size = int((num_images_labeled + num_images_unlabeled)/3)\n",
    "\n",
    "# Workflow Inputs:\n",
    "iou_threshold = 0.4\n",
    "decision_making_mode = 'thermal' # options are 'all', 'thermal', and 'webcam'\n",
    "max_results = 3\n",
    "score_threshold = 0.5 # Will set higher to mitigate random sensor agreement due to sheer\n",
    "                        # number of garbage baxes being returned otherwise\n",
    "# Read in ground truth\n",
    "with open(analysis_dataset_dir.joinpath('labels.json'), 'r') as json_file:\n",
    "    ground_truth = json.load(json_file)\n",
    "    \n",
    "# Initialize FUSED class\n",
    "fused = Fused_Workflow(iou_threshold, decision_making_mode, max_results, score_threshold)\n",
    "\n",
    "# Initialize individual arrays\n",
    "idv_lidar_det_results = np.empty((size, 2), dtype=object)\n",
    "idv_thermal_det_results = np.empty((size, 2), dtype=object)\n",
    "idv_webcam_det_results = np.empty((size, 2), dtype=object)\n",
    "\n",
    "# Initialize fused arrays\n",
    "fused_lidar_det_results = np.empty((size, 2), dtype=object)\n",
    "fused_thermal_det_results = np.empty((size, 2), dtype=object)\n",
    "fused_webcam_det_results = np.empty((size, 2), dtype=object)\n",
    "\n",
    "# Gather results for both labeled and unlabeled images\n",
    "labeled_dir = analysis_dataset_dir.joinpath('labeled_images')\n",
    "unlabeled_dir = analysis_dataset_dir.joinpath('unlabeled_images')\n",
    "i = 0\n",
    "i, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results = gather_results(i, labeled_dir, fused, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results)\n",
    "i, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results = gather_results(i, unlabeled_dir, fused, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results)\n",
    "    \n",
    "# Calculate AP\n",
    "ap_idv_lidar, lidar_gt = ap(idv_lidar_det_results, ground_truth, iou_threshold, fused, 'Individual LiDAR')\n",
    "ap_idv_thermal, thermal_gt = ap(idv_thermal_det_results, ground_truth, iou_threshold, fused, 'Individual Thermal')\n",
    "ap_idv_webcam, webcam_gt = ap(idv_webcam_det_results, ground_truth, iou_threshold, fused, 'Individual Webcam')\n",
    "ap_fused_lidar, lidar_gt = ap(fused_lidar_det_results, ground_truth, iou_threshold, fused, 'Fused LiDAR')\n",
    "ap_fused_thermal, thermal_gt = ap(fused_thermal_det_results, ground_truth, iou_threshold, fused, 'Fused Thermal')\n",
    "ap_fused_webcam, webcam_gt = ap(fused_webcam_det_results, ground_truth, iou_threshold, fused, 'Fused Webcam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thermal_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webcam_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
