{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from numpy import array\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from numpy.linalg import inv\n",
    "from mediapipe.tasks.python.components.containers import Detection, DetectionResult, BoundingBox, Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fused_Workflow:\n",
    "    def __init__(self, iou_threshold, decision_making_mode, max_results, score_threshold):\n",
    "        \"\"\"Project FUSED Workflow Algorithm (refactored for analysis)\n",
    "\n",
    "        Args:\n",
    "            iou_threshold (float): Intersection-over-Union fraction threshold for evaluating bounding box overlaps\n",
    "            decision_making_mode (str): Which sensors need to agree for the detection to be considered valid? 'all', 'thermal', or 'webcam'\n",
    "            score_threshold (float): Minimum confidence score that the models must have for the detection to be kept\n",
    "        \"\"\"\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.decision_making_mode = decision_making_mode\n",
    "        \n",
    "        # Initialize the object detection models\n",
    "        base_options_webcam = python.BaseOptions(model_asset_path='/project_fused/models/efficientdet_lite0.tflite')\n",
    "        options_webcam = vision.ObjectDetectorOptions(base_options=base_options_webcam, running_mode=vision.RunningMode.IMAGE, max_results=max_results, score_threshold=score_threshold)\n",
    "        self.webcam_detector = vision.ObjectDetector.create_from_options(options_webcam)\n",
    "\n",
    "        # Initialize the thermal object detection model\n",
    "        base_options_thermal = python.BaseOptions(model_asset_path='/project_fused/models/thermal.tflite')\n",
    "        options_thermal = vision.ObjectDetectorOptions(base_options=base_options_thermal, running_mode=vision.RunningMode.IMAGE, max_results=max_results, score_threshold=score_threshold)\n",
    "        self.thermal_detector = vision.ObjectDetector.create_from_options(options_thermal)\n",
    "\n",
    "        # Initialize the LiDAR object detection model\n",
    "        base_options_lidar = python.BaseOptions(model_asset_path='/project_fused/models/lidar.tflite')\n",
    "        options_lidar = vision.ObjectDetectorOptions(base_options=base_options_lidar, running_mode=vision.RunningMode.IMAGE, max_results=max_results, score_threshold=score_threshold)\n",
    "        self.lidar_detector = vision.ObjectDetector.create_from_options(options_lidar)\n",
    "\n",
    "        # Define the transformation matrices\n",
    "        # Set extrinsic translation matrices based on physical measurements, no z translation assumed\n",
    "        self.T_l2t = array([[1, 0, 0, 0.028],\n",
    "                            [0, 1, 0, -0.038],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "        self.T_l2w = array([[1, 0, 0, 0.083],\n",
    "                            [0, 1, 0, -0.035],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "        # Set extrinsic rotation matrices from stereo calibration\n",
    "        self.R_t2cₜ = array([[0.804905, 0.593319, 0.010014],\n",
    "                             [-0.588094, 0.795337, 0.146920],\n",
    "                             [0.079206, -0.124146, 0.989098]])\n",
    "        self.R_l2cₜ = array([[0.813639, 0.571181, 0.108367],\n",
    "                             [-0.580035, 0.784919, 0.217856],\n",
    "                             [0.039376, -0.240112, 0.969946]])\n",
    "        self.R_w2cᵣ = array([[0.903012, -0.397065, -0.164039],\n",
    "                             [0.397183, 0.917127, -0.033513],\n",
    "                             [0.163751, -0.034891, 0.985884]])\n",
    "        self.R_l2cᵣ = array([[0.909488, -0.399788, -0.114025],\n",
    "                             [0.399705, 0.916314, -0.024592],\n",
    "                             [0.114314, -0.023211, 0.993173]])\n",
    "\n",
    "        # Set intrinsic matrices for the three sensors\n",
    "        self.Kₗ = array([[205.046875, 0.0, 107.55435943603516],\n",
    "                         [0.0, 205.046875, 82.43924713134766],\n",
    "                         [0.0, 0.0, 1.0]])\n",
    "        self.Kₜ = array([[161.393925, 0.000000, 78.062273],\n",
    "                         [0.000000, 161.761028, 59.925115], \n",
    "                         [0.000000, 0.000000, 1.000000]])\n",
    "        self.Kᵣ = array([[446.423112, 0.000000, 163.485603], \n",
    "                         [0.000000, 446.765896, 131.217485],\n",
    "                         [0.000000, 0.000000, 1.000000]])\n",
    "\n",
    "        # Initialize visualization parameters\n",
    "        self.TEXT_COLOR = (255, 255, 255)\n",
    "        self.BOX_THICKNESS = 3\n",
    "        self.MARGIN = 5\n",
    "        self.ROW_SIZE = -15\n",
    "        self.FONT_SIZE = 0.5\n",
    "        self.FONT_THICKNESS = 1\n",
    "        \n",
    "        # Initialize image resolutions\n",
    "        self.lidar_width = 224\n",
    "        self.lidar_height = 172\n",
    "        self.thermal_width = 160\n",
    "        self.thermal_height = 120\n",
    "        self.webcam_width = 320\n",
    "        self.webcam_height = 240\n",
    "        \n",
    "    def fuse(self, lidar_image, thermal_image, webcam_image):\n",
    "        \"\"\"Main FUSED workflow function: perform fusion based alignment of object detection\n",
    "        bounding boxes on synchronized LiDAR, thermal, and webcam images for decision making\n",
    "\n",
    "        Args:\n",
    "            lidar_image (OpenCV image): Synchronized LiDAR image\n",
    "            thermal_image (OpenCV image): Synchronized thermal image\n",
    "            webcam_image (OpenCV image): Synchronized webcam image\n",
    "\n",
    "        Returns:\n",
    "            detection results (tuple): 6 detection results - 3 from individual sensors, 3 from FUSED workflow\n",
    "        \"\"\"\n",
    "        # Perform LiDAR image processing\n",
    "        max_depth = np.max(lidar_image)\n",
    "        lidar_image_clipped = np.clip(lidar_image, 0, max_depth)\n",
    "        lidar_image_mm = lidar_image_clipped * 1000\n",
    "        lidar_image_normalized = cv2.normalize(lidar_image_mm, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "        lidar_image_8bit = cv2.convertScaleAbs(lidar_image_normalized, alpha=(255.0 / np.max(lidar_image_normalized)))\n",
    "        lidar_image_equalized = cv2.equalizeHist(lidar_image_8bit)\n",
    "\n",
    "        # Convert OpenCV images to RGB format\n",
    "        lidar_image_rgb = cv2.cvtColor(lidar_image_equalized, cv2.COLOR_GRAY2RGB)\n",
    "        thermal_image_rgb = cv2.cvtColor(thermal_image, cv2.COLOR_GRAY2RGB)\n",
    "        webcam_image_rgb = cv2.cvtColor(webcam_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert RGB images to MediaPipe images\n",
    "        lidar_image_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=lidar_image_rgb)\n",
    "        thermal_image_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=thermal_image_rgb)\n",
    "        webcam_image_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=webcam_image_rgb)\n",
    "\n",
    "        # Perform object detection on the MediaPipe images\n",
    "        lidar_detection_result = self.lidar_detector.detect(lidar_image_mp)\n",
    "        thermal_detection_result = self.thermal_detector.detect(thermal_image_mp)\n",
    "        webcam_detection_result = self.webcam_detector.detect(webcam_image_mp)\n",
    "\n",
    "        # Initialize lists for keeping track of detections to be kept out of the next iteration\n",
    "        thermal_exclude_idx = []\n",
    "        webcam_exclude_idx = []\n",
    "        \n",
    "        # Initialize detection lists for the fused results\n",
    "        lidar_fused_detections = []\n",
    "        thermal_fused_detections = []\n",
    "        webcam_fused_detections = []\n",
    "\n",
    "        # For loop through each LiDAR detection in the detection result\n",
    "        if lidar_detection_result.detections:\n",
    "            for detection in lidar_detection_result.detections:\n",
    "                if detection.categories[0].category_name != 'Person':\n",
    "                    continue\n",
    "                # Define the top left and bottom right points of the detection\n",
    "                bbox = detection.bounding_box\n",
    "                x1, y1 = bbox.origin_x, bbox.origin_y # Top left\n",
    "                x2, y2 = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height # Bottom right\n",
    "\n",
    "                # Find the depth on the LiDAR image at the center of the box\n",
    "                uₗ = round((x1 + x2) / 2)\n",
    "                vₗ = round((y1 + y2) / 2)\n",
    "                try:\n",
    "                    zₗ = lidar_image[vₗ,uₗ]\n",
    "                except IndexError:\n",
    "                    if uₗ >= lidar_image.shape[1]:\n",
    "                        uₗ = lidar_image.shape[1] - 1\n",
    "                    if vₗ >= lidar_image.shape[0]:\n",
    "                        vₗ = lidar_image.shape[0] - 1\n",
    "                    zₗ = lidar_image[vₗ, uₗ]\n",
    "\n",
    "                # If depth is not zero, then compute transformed u and v on webcam and thermal frames\n",
    "                if zₗ > 1E-3:\n",
    "                    x1ₗₜ, y1ₗₜ, x1ₗᵣ, y1ₗᵣ = self.transform(zₗ, x1, y1)\n",
    "                    x2ₗₜ, y2ₗₜ, x2ₗᵣ, y2ₗᵣ = self.transform(zₗ, x2, y2)\n",
    "\n",
    "                    # Calculate IoU between the mapped bounding box and all detection results from the webcam and thermal images\n",
    "                    thermal_mapped_box = (x1ₗₜ, y1ₗₜ, x2ₗₜ, y2ₗₜ)\n",
    "                    if thermal_detection_result.detections and len(thermal_detection_result.detections) != len(thermal_exclude_idx):\n",
    "                        thermal_ious = []\n",
    "                        for idxₜ, thermal_detection in enumerate(thermal_detection_result.detections):\n",
    "                            if thermal_detection.categories[0].category_name != 'Person':\n",
    "                                continue\n",
    "                            if idxₜ in thermal_exclude_idx:\n",
    "                                continue\n",
    "                            thermal_bbox = thermal_detection.bounding_box\n",
    "                            x1ₜ, y1ₜ = thermal_bbox.origin_x, thermal_bbox.origin_y\n",
    "                            x2ₜ, y2ₜ = thermal_bbox.origin_x + thermal_bbox.width, thermal_bbox.origin_y + thermal_bbox.height\n",
    "                            thermal_box = (x1ₜ, y1ₜ, x2ₜ, y2ₜ)\n",
    "                            thermal_ious.append(self.calc_iou(thermal_box, thermal_mapped_box))\n",
    "\n",
    "                    webcam_mapped_box = (x1ₗᵣ, y1ₗᵣ, x2ₗᵣ, y2ₗᵣ)\n",
    "                    if webcam_detection_result.detections and len(webcam_detection_result.detections) != len(webcam_exclude_idx):\n",
    "                        webcam_ious = []\n",
    "                        for idxᵣ, webcam_detection in enumerate(webcam_detection_result.detections):\n",
    "                            if webcam_detection.categories[0].category_name != 'person':\n",
    "                                continue\n",
    "                            if idxᵣ in webcam_exclude_idx:\n",
    "                                continue\n",
    "                            webcam_bbox = webcam_detection.bounding_box\n",
    "                            x1ᵣ, y1ᵣ = webcam_bbox.origin_x, webcam_bbox.origin_y\n",
    "                            x2ᵣ, y2ᵣ = webcam_bbox.origin_x + webcam_bbox.width, webcam_bbox.origin_y + webcam_bbox.height\n",
    "                            webcam_box = (x1ᵣ, y1ᵣ, x2ᵣ, y2ᵣ)\n",
    "                            webcam_ious.append(self.calc_iou(webcam_box, webcam_mapped_box))\n",
    "\n",
    "                    # Choose the thermal or webcam detection result corresponding to the LiDAR mapped result whose IoU is the \n",
    "                    # largest and also above the defined Combination IoU threshold. In the next iterations of the for loop,\n",
    "                    # the thermal or webcam detection result that was chosen should not be chosen again to match with another\n",
    "                    # LiDAR mapped result\n",
    "                    valid_thermal_iou = None\n",
    "                    valid_webcam_iou = None\n",
    "                    if thermal_detection_result.detections and len(thermal_detection_result.detections) != len(thermal_exclude_idx):\n",
    "                        max_thermal_iou = max(thermal_ious)\n",
    "                        max_thermal_iou_index = thermal_ious.index(max_thermal_iou)\n",
    "                        valid_thermal_iou = 0\n",
    "                        if max_thermal_iou > self.iou_threshold:\n",
    "                            valid_thermal_iou, valid_thermal_idx = max_thermal_iou, max_thermal_iou_index\n",
    "                            thermal_exclude_idx.append(valid_thermal_idx)\n",
    "                    \n",
    "                    if webcam_detection_result.detections and len(webcam_detection_result.detections) != len(webcam_exclude_idx):\n",
    "                        max_webcam_iou = max(webcam_ious)\n",
    "                        max_webcam_iou_index = webcam_ious.index(max_webcam_iou)\n",
    "                        valid_webcam_iou = 0\n",
    "                        if max_webcam_iou > self.iou_threshold:\n",
    "                            valid_webcam_iou, valid_webcam_idx = max_webcam_iou, max_webcam_iou_index\n",
    "                            webcam_exclude_idx.append(valid_webcam_idx)\n",
    "\n",
    "                    # Depending on the decision making mode, choose to either keep the mapped result or not based on whether there \n",
    "                    # is agreement between all 3 or only two sensors\n",
    "                    # If the mapped result is not being kept, then go to the next iteration of the loop. If it is being kept, then\n",
    "                    # keep the original detections that have been agreed upon according to the decision making mode. For the \n",
    "                    # detection that has not been agreed upon, check if it agrees with LiDAR. If it does, keep it. If it does not,\n",
    "                    # then use the mapped LiDAR detection onto the appropriate camera frame instead\n",
    "                    # Store the three fused detection results at each iteration\n",
    "                    if self.decision_making_mode == 'all':\n",
    "                        if valid_thermal_iou and valid_webcam_iou:\n",
    "                            lidar_fused_detections.append(self.truncate(detection, self.lidar_width, self.lidar_height))\n",
    "                            thermal_fused_detections.append(self.truncate(thermal_detection_result.detections[valid_thermal_idx], self.thermal_width, self.thermal_height))\n",
    "                            webcam_fused_detections.append(self.truncate(webcam_detection_result.detections[valid_webcam_idx], self.webcam_width, self.webcam_height))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    if self.decision_making_mode == 'thermal':\n",
    "                        if valid_thermal_iou:\n",
    "                            lidar_fused_detections.append(self.truncate(detection, self.lidar_width, self.lidar_height))\n",
    "                            thermal_fused_detections.append(self.truncate(thermal_detection_result.detections[valid_thermal_idx], self.thermal_width, self.thermal_height))\n",
    "                            if valid_webcam_iou:\n",
    "                                webcam_fused_detections.append(self.truncate(webcam_detection_result.detections[valid_webcam_idx], self.webcam_width, self.webcam_height))\n",
    "                            else:\n",
    "                                webcam_fused_detections.append(self.truncate(self.create_detection(detection, webcam_mapped_box), self.webcam_width, self.webcam_height))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    if self.decision_making_mode == 'webcam':\n",
    "                        if valid_webcam_iou:\n",
    "                            lidar_fused_detections.append(self.truncate(detection, self.lidar_width, self.lidar_height))\n",
    "                            webcam_fused_detections.append(self.truncate(webcam_detection_result.detections[valid_webcam_idx], self.webcam_width, self.webcam_height))\n",
    "                            if valid_thermal_iou:\n",
    "                                thermal_fused_detections.append(self.truncate(thermal_detection_result.detections[valid_thermal_idx], self.thermal_width, self.thermal_height))\n",
    "                            else:\n",
    "                                thermal_fused_detections.append(self.truncate(self.create_detection(detection, thermal_mapped_box), self.thermal_width, self.thermal_height))\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        # With all of the fused detections, create detection results\n",
    "        if not lidar_fused_detections:\n",
    "            lidar_fused_detection_result = None\n",
    "        else:\n",
    "            lidar_fused_detection_result = DetectionResult(detections=lidar_fused_detections)\n",
    "            \n",
    "        if not thermal_fused_detections:\n",
    "            thermal_fused_detection_result = None\n",
    "        else:\n",
    "            thermal_fused_detection_result = DetectionResult(detections=thermal_fused_detections)\n",
    "            \n",
    "        if not webcam_fused_detections:\n",
    "            webcam_fused_detection_result = None\n",
    "        else:\n",
    "            webcam_fused_detection_result = DetectionResult(detections=webcam_fused_detections)\n",
    "            \n",
    "        return lidar_detection_result, thermal_detection_result, webcam_detection_result, lidar_fused_detection_result, thermal_fused_detection_result, webcam_fused_detection_result\n",
    "            \n",
    "    def transform(self, zₗ, uₗ, vₗ):\n",
    "        \"\"\"Perform transformations to map a pixel from the LiDAR's camera frame onto the thermal and webcam camera frames\n",
    "\n",
    "        Args:\n",
    "            zₗ (float): Depth of the pixel, in meters\n",
    "            uₗ (int): LiDAR pixel coordinate on the x axis\n",
    "            vₗ (int): LiDAR pixel coordinate on the y axis\n",
    "\n",
    "        Returns:\n",
    "            uₜ, vₜ, uᵣ, vᵣ (tuple): Thermal and webcam pixel coordinates, respectively\n",
    "        \"\"\"\n",
    "        # Calculate the 3D physical coordinate of the center of the LiDAR image\n",
    "        pₗ = array([uₗ, vₗ, 1])\n",
    "        l̂ₗ = inv(self.Kₗ) @ pₗ\n",
    "        r̄ₗ = zₗ * l̂ₗ\n",
    "        \n",
    "        # Perform extrinsic translations to the thermal sensor and webcam\n",
    "        r̄ₜ = (inv(self.R_t2cₜ) @ (self.R_l2cₜ @ r̄ₗ)) + array([self.T_l2t[0, 3], self.T_l2t[1, 3], 0]).T\n",
    "        r̄ᵣ = (inv(self.R_w2cᵣ) @ (self.R_l2cᵣ @ r̄ₗ)) + array([self.T_l2w[0, 3], self.T_l2w[1, 3], 0]).T\n",
    "        \n",
    "        # Transform 3D coordinate to thermal and webcam pixel coordinates\n",
    "        r̃ₜ = array([r̄ₜ[0]/r̄ₜ[2], r̄ₜ[1]/r̄ₜ[2], r̄ₜ[2]/r̄ₜ[2]])\n",
    "        r̃ᵣ = array([r̄ᵣ[0]/r̄ᵣ[2], r̄ᵣ[1]/r̄ᵣ[2], r̄ᵣ[2]/r̄ᵣ[2]])\n",
    "        pₜ = self.Kₜ @ r̃ₜ\n",
    "        pᵣ = self.Kᵣ @ r̃ᵣ\n",
    "        uₜ, vₜ = pₜ[0], pₜ[1]\n",
    "        uᵣ, vᵣ = pᵣ[0], pᵣ[1]\n",
    "        \n",
    "        return uₜ, vₜ, uᵣ, vᵣ\n",
    "    \n",
    "    def calc_iou(self, box_1, box_2):\n",
    "        \"\"\"Calculate the Intersection-over-Union between two bounding boxes\n",
    "\n",
    "        Args:\n",
    "            box_1 (tuple): Tuple of top-left and bottom-right pixel coordinates for the first bounding box\n",
    "            box_2 (tuple): Tuple of top-left and bottom-right pixel coordinates for the second bounding box\n",
    "\n",
    "        Returns:\n",
    "            iou (float): Intersection-over-Union ratio\n",
    "        \"\"\"\n",
    "        # Get corner values from both boxes\n",
    "        x1, y1, x2, y2 = box_1\n",
    "        x3, y3, x4, y4 = box_2\n",
    "        \n",
    "        # Get corner values for the intersection box\n",
    "        x_inter1 = max(x1, x3)\n",
    "        y_inter1 = max(y1, y3)\n",
    "        x_inter2 = min(x2, x4)\n",
    "        y_inter2 = min(y2, y4)\n",
    "        \n",
    "        # Calculate the area of the intersection box\n",
    "        width_inter = max(0, x_inter2 - x_inter1)\n",
    "        height_inter = max(0, y_inter2 - y_inter1)\n",
    "        area_inter = width_inter * height_inter\n",
    "        \n",
    "        # Calculate the areas of the two boxes\n",
    "        width_box1 = x2 - x1\n",
    "        height_box1 = y2 - y1\n",
    "        width_box2 = x4 - x3\n",
    "        height_box2 = y4 - y3\n",
    "        area_box1 = width_box1 * height_box1\n",
    "        area_box2 = width_box2 * height_box2\n",
    "        \n",
    "        # Calculate the area of the full union of the two boxes\n",
    "        area_union = area_box1 + area_box2 - area_inter\n",
    "        \n",
    "        # If union area is zero, return 0\n",
    "        if area_union == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate the IoU\n",
    "        iou = area_inter / area_union\n",
    "\n",
    "        return iou\n",
    "    \n",
    "    def truncate(self, detection, img_width, img_height): \n",
    "        \"\"\"Truncate a bounding box detection so that the coordinates remain within the image\n",
    "        and don't go over the edges\n",
    "\n",
    "        Args:\n",
    "            detection (object): MediaPipe detection object\n",
    "            img_width (int): Image width (pixels)\n",
    "            img_height (int): Image height (pixels)\n",
    "\n",
    "        Returns:\n",
    "            new_detection (object): Updated MediaPipe detection object with truncated bounding box coordinates\n",
    "        \"\"\"\n",
    "        # Extract bounding box coordinates\n",
    "        bbox = detection.bounding_box\n",
    "        box_origin_x = bbox.origin_x\n",
    "        box_origin_y = bbox.origin_y\n",
    "        box_width = bbox.width\n",
    "        box_height = bbox.height\n",
    "        \n",
    "        # Get image width and length\n",
    "        if box_origin_x + box_width > img_width:\n",
    "            overhang_x = box_origin_x + box_width - img_width\n",
    "            box_width = box_width - overhang_x\n",
    "            \n",
    "        if box_origin_x < 0:\n",
    "            box_origin_x = 0\n",
    "            \n",
    "        if box_origin_y + box_height > img_height:\n",
    "            overhang_y = box_origin_y + box_width - img_height\n",
    "            box_height = box_height - overhang_y\n",
    "            \n",
    "        if box_origin_y < 0:\n",
    "            box_origin_y = 0\n",
    "        \n",
    "        #Might need to check the above code for syntax issues. Also just yapping to see if the code will push\n",
    "    \n",
    "        # Redefine bounding box coordinates\n",
    "        detection.bounding_box.origin_x = box_origin_x\n",
    "        detection.bounding_box.origin_y = box_origin_y\n",
    "        detection.bounding_box.width = box_width\n",
    "        detection.bounding_box.height = box_height\n",
    "        \n",
    "        return detection\n",
    "    \n",
    "    def create_detection(self, lidar_detection, other_detection_box):\n",
    "        \"\"\"Create a MediaPipe detection object\n",
    "\n",
    "        Args:\n",
    "            lidar_detection (detection object): Original LiDAR MediaPipe detection object\n",
    "            other_detection_box (tuple): Tuple with bounding box coordinates for mapped LiDAR box onto either\n",
    "            webcam or thermal camera frames\n",
    "\n",
    "        Returns:\n",
    "            detection (detection object): MediaPipe detection object for the mapped LiDAR box onto one of the \n",
    "            two other camera frames\n",
    "        \"\"\"\n",
    "        # Get bounding box coordinates and score\n",
    "        x1, y1, x2, y2 = other_detection_box\n",
    "        x1, y1, x2, y2 = round(x1), round(y1), round(x2), round(y2)\n",
    "        score = lidar_detection.categories[0].score\n",
    "        \n",
    "        # Define data dictionary\n",
    "        data = {\n",
    "            \"bounding_box\": (x1, y1, x2 - x1, y2 - y1),\n",
    "            \"score\": score,\n",
    "            \"category_name\": \"Person\"\n",
    "        }\n",
    "        \n",
    "        # Use MediaPipe functions to build the detection object\n",
    "        bounding_box = BoundingBox(\n",
    "            origin_x=data[\"bounding_box\"][0],\n",
    "            origin_y=data[\"bounding_box\"][1],\n",
    "            width=data[\"bounding_box\"][2],\n",
    "            height=data[\"bounding_box\"][3]\n",
    "        )\n",
    "        \n",
    "        category = Category(\n",
    "            index=None, # Optional\n",
    "            score=data[\"score\"],\n",
    "            display_name=None, # Optional\n",
    "            category_name=data[\"category_name\"]\n",
    "        )\n",
    "        \n",
    "        detection = Detection(\n",
    "            bounding_box=bounding_box,\n",
    "            categories=[category],\n",
    "            keypoints=[] # Optional\n",
    "        )\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def visualize(self, image, detection_result):\n",
    "        \"\"\"Draw bounding boxes on OpenCV images\n",
    "\n",
    "        Args:\n",
    "            image (OpenCV image): OpenCV image that the box must be drawn on\n",
    "            detection_result (MediaPipe detection result): MediaPipe detection result containing bounding box coordinates and labels\n",
    "\n",
    "        Returns:\n",
    "            image (OpenCV image): OpenCV image with the boxes and labels drawn\n",
    "        \"\"\"\n",
    "        # Start for loop for all detections \n",
    "        for detection in detection_result.detections:\n",
    "            # Draw the bounding box\n",
    "            bbox = detection.bounding_box\n",
    "            start_point = bbox.origin_x, bbox.origin_y\n",
    "            end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
    "            cv2.rectangle(image, start_point, end_point, self.TEXT_COLOR, self.BOX_THICKNESS)\n",
    "\n",
    "            # Write the label\n",
    "            category = detection.categories[0]\n",
    "            category_name = category.category_name\n",
    "            probability = round(category.score, 2)\n",
    "            result_text = category_name + ' (' + str(probability) + ')'\n",
    "            text_location = (self.MARGIN + bbox.origin_x,\n",
    "                                self.MARGIN + self.ROW_SIZE + bbox.origin_y)\n",
    "            cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_DUPLEX,\n",
    "                        self.FONT_SIZE, self.TEXT_COLOR, self.FONT_THICKNESS, cv2.LINE_AA)\n",
    "            \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_results(directory, fused, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, \\\n",
    "        fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results):\n",
    "    \"\"\"Loop through and sort the images required for the FUSED workflow, call the FUSED workflow, and\n",
    "    store detection results and image filenames in arrays\n",
    "\n",
    "    Args:\n",
    "        directory (Path object): Path for the directory containing the images\n",
    "        fused (class): Instance of the Fused_Workflow class\n",
    "        idv_lidar_det_results (numpy array): Empty numpy array\n",
    "        idv_thermal_det_results (numpy array): Empty numpy array\n",
    "        idv_webcam_det_results (numpy array): Empty numpy array\n",
    "        fused_thermal_det_results (numpy array): Empty numpy array\n",
    "        fused_webcam_det_results (numpy array): Empty numpy array\n",
    "\n",
    "    Returns:\n",
    "        detection results (tuple): All numpy arrays with detections and image filenames added\n",
    "    \"\"\"\n",
    "    # Set iterator\n",
    "    i = 0\n",
    "    \n",
    "    # For loop through each set of synchronized images\n",
    "    for path in directory.glob('*'):\n",
    "        # Extract category\n",
    "        category = str(path).rsplit('_')[-3]\n",
    "        \n",
    "        # If LiDAR, grab the two corresponding thermal and webcam paths\n",
    "        if category == 'lidar': \n",
    "            # Redefine path variable\n",
    "            lidar_path = path\n",
    "            \n",
    "            # Pull scenario and number for matching files\n",
    "            scenario = '_'.join(str(path).rsplit('/')[-1].rsplit('_')[:-3])\n",
    "            number = str(path).rsplit('_')[-1].rsplit('.')[0]\n",
    "           \n",
    "            # Thermal and webcam path re-creation\n",
    "            thermal_path = directory.joinpath(scenario + '_thermal_image_' + number + '.png')\n",
    "            webcam_path = directory.joinpath(scenario + '_webcam_image_' + number + '.png')\n",
    "           \n",
    "            # Read in images\n",
    "            lidar_image = cv2.imread(lidar_path, cv2.IMREAD_UNCHANGED)\n",
    "            thermal_image = cv2.imread(thermal_path, cv2.IMREAD_UNCHANGED)\n",
    "            webcam_image = cv2.imread(webcam_path, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            # Call the fuse method\n",
    "            idv_lidar, idv_thermal, idv_webcam, fused_lidar, fused_thermal, fused_webcam = fused.fuse(lidar_image, thermal_image, webcam_image)\n",
    "            \n",
    "            # Add individual results to matrices\n",
    "            idv_lidar_det_results[i,0] = lidar_path\n",
    "            idv_lidar_det_results[i,1] = idv_lidar\n",
    "            idv_thermal_det_results[i,0] = thermal_path\n",
    "            idv_thermal_det_results[i,1] = idv_thermal\n",
    "            idv_webcam_det_results[i,0] = webcam_path\n",
    "            idv_webcam_det_results[i,1] = idv_webcam\n",
    "            \n",
    "            # Add fused results to matrices\n",
    "            fused_lidar_det_results[i,0] = lidar_path\n",
    "            fused_lidar_det_results[i,1] = fused_lidar\n",
    "            fused_thermal_det_results[i,0] = thermal_path\n",
    "            fused_thermal_det_results[i,1] = fused_thermal\n",
    "            fused_webcam_det_results[i,0] = webcam_path\n",
    "            fused_webcam_det_results[i,1] = fused_webcam\n",
    "            \n",
    "            # Update iterator\n",
    "            i += 1\n",
    "            \n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    return idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738959962.586536    4843 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1738959962.687553    4843 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\n",
      "I0000 00:00:1738959962.863984    4843 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\n"
     ]
    }
   ],
   "source": [
    "# Get the number of images in the chosen test directory\n",
    "analysis_dataset_dir = Path('/project_fused/data/Analysis_Dataset')\n",
    "num_images_labeled = len(list(analysis_dataset_dir.joinpath('labeled_images').glob('*')))\n",
    "num_images_unlabeled = len(list(analysis_dataset_dir.joinpath('unlabeled_images').glob('*')))\n",
    "\n",
    "# Workflow Inputs:\n",
    "iou_threshold = 0.4\n",
    "decision_making_mode = 'thermal' # options are 'all', 'thermal', and 'webcam'\n",
    "max_results = 3\n",
    "score_threshold = 0.5 # Will set higher to mitigate random sensor agreement due to sheer\n",
    "                        # number of garbage baxes being returned otherwise\n",
    "\n",
    "# Initialize FUSED class\n",
    "fused = Fused_Workflow(iou_threshold, decision_making_mode, max_results, score_threshold)\n",
    "\n",
    "# Initialize individual arrays\n",
    "idv_lidar_det_results = np.empty((num_images_labeled + num_images_unlabeled, 2), dtype=object)\n",
    "idv_thermal_det_results = np.empty((num_images_labeled + num_images_unlabeled, 2), dtype=object)\n",
    "idv_webcam_det_results = np.empty((num_images_labeled + num_images_unlabeled, 2), dtype=object)\n",
    "\n",
    "# Initialize fused arrays\n",
    "fused_lidar_det_results = np.empty((num_images_labeled + num_images_unlabeled, 2), dtype=object)\n",
    "fused_thermal_det_results = np.empty((num_images_labeled + num_images_unlabeled, 2), dtype=object)\n",
    "fused_webcam_det_results = np.empty((num_images_labeled + num_images_unlabeled, 2), dtype=object)\n",
    "\n",
    "# Gather results for both labeled and unlabeled images\n",
    "labeled_dir = analysis_dataset_dir.joinpath('labeled_images')\n",
    "unlabeled_dir = analysis_dataset_dir.joinpath('unlabeled_images')\n",
    "idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, \\\n",
    "    fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results = \\\n",
    "    gather_results(labeled_dir, fused, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, \\\n",
    "    fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results)\n",
    "idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, \\\n",
    "    fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results = \\\n",
    "    gather_results(unlabeled_dir, fused, idv_lidar_det_results, idv_thermal_det_results, idv_webcam_det_results, \\\n",
    "    fused_lidar_det_results, fused_thermal_det_results, fused_webcam_det_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/fused_dev/data/Analysis_Dataset/labeled_images/Testing_Gunner_Walking_lidar_image_81.tiff')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_lidar_det_results[39,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
